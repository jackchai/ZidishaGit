{
 "metadata": {
  "name": "",
  "signature": "sha256:b8cefb76d5271ac98d77fa032a53f6a735991d241edb02af1cb184ac86a27de4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You might not need all of these packages. For the most part a lot of these are used for plots to check\n",
      "# if your model is running well. I left the plots and other stuff in just for now but if you feel like you\n",
      "# do not need then, you should take some of these packages out\n",
      "import pandas as pd\n",
      "import pandas.io.sql as psql\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as mdates\n",
      "from datetime import datetime\n",
      "import MySQLdb as mdb \n",
      "import numpy as np\n",
      "import time\n",
      "import statsmodels.api as sm\n",
      "from patsy import dmatrices\n",
      "from sklearn import svm\n",
      "from sklearn.externals import joblib\n",
      "import pickle as pickle\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from scipy.stats import gaussian_kde\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Connection here needs to be changed. Note that for now, I am connected to old databases\n",
      "con = mdb.connect(host = 'localhost', user = 'root', passwd = 'pptz/90275', db = 'zidisha')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extraction from these tables also need to be changed. I am again using old tables and some of the names are different.\n",
      "# I left it like this for now because I know that many of the columns are going to change\n",
      "with con:\n",
      "    cur = con.cursor()\n",
      "    sql = \"SELECT * FROM excrate\"\n",
      "    excratedf = psql.frame_query(sql, con, coerce_float = True)\n",
      "\n",
      "    sql = \"SELECT * FROM borrowers\"\n",
      "    borrowers = psql.frame_query(sql, con, coerce_float = True)\n",
      "    \n",
      "    sql = \"SELECT * FROM repaymentschedule\"\n",
      "    rsh = psql.frame_query(sql, con, coerce_float = True)\n",
      "    \n",
      "    sql = \"SELECT * FROM loanapplic\"\n",
      "    loanapplic = psql.frame_query(sql, con, coerce_float = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is from the repayment schedule table\n",
      "# We are trying to get rid of lines in which there are no values otherwise this will throw error later on\n",
      "# Amount = Amount expected during each payment. Paid amount is amount for each installment\n",
      "rshamount = rsh.amount\n",
      "rshamount[np.isnan(rshamount)] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rshpaidamt = rsh.paidamt\n",
      "rshpaidamt[np.isnan(rshpaidamt)] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loss is calculated as the amount paid - amount lost\n",
      "rsh['netloss'] = pd.Series(rshpaidamt - rshamount, index=rsh.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To allow for 2 month grace period, we are going to only look at data that was at most 2 months ago.\n",
      "# Currently, this is calculated as 60 days before the current time\n",
      "currdate = datetime.now()\n",
      "twomonthtime = time.mktime(currdate.timetuple()) - 60*24*3600\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Isolating only the rows that fit within the time\n",
      "rshtrunc = rsh[rsh.duedate.apply(float)<twomonthtime]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We are going to merging some tables to centralize values for the loans\n",
      "rshgroup = rsh.groupby('loanid')\n",
      "rshtruncgroup = rshtrunc.groupby('loanid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lossamt = rshtruncgroup['netloss'].apply(sum)\n",
      "lossamt = lossamt.reset_index()\n",
      "lossamt = lossamt.rename(columns = {0:'lossamt'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expectedamt = rshtruncgroup['amount'].apply(sum)\n",
      "expectedamt = expectedamt.reset_index()\n",
      "expectedamt = expectedamt.rename(columns = {0:'expectedamt'})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paidamt = rshtruncgroup['paidamt'].apply(sum)\n",
      "paidamt = paidamt.reset_index()\n",
      "paidamt = paidamt.rename(columns = {0:'paidamt'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By fraction lost, this means that the fraction payments a person recieved before defaulting\n",
      "# For some people, they will actually have paid a little bit more, and this counts as full repayment so we set it to zero\n",
      "fractionlost = (lossamt.lossamt)/np.abs(expectedamt.expectedamt)\n",
      "fractionlost[fractionlost > 0.0]  = 0.0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Again, we are centralizing the information. Note, I want risk to be between 0 to 1 which is why we use the negative\n",
      "compinfo = expectedamt\n",
      "compinfo['lossamt'] = lossamt.lossamt\n",
      "compinfo['fractionlost'] = -fractionlost\n",
      "compinfo['paidamt'] = paidamt.paidamt\n",
      "compinfo = compinfo[compinfo.expectedamt != 0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This entire section is optional. It depends on how you want to train the svm. We can categorize by risk or by supposed interest rate\n",
      "# I do not recommend this because dividing by risk enhances the error for interest rate determination\n",
      "compinfo['expectedint'] = 1\n",
      "expectedint = compinfo.expectedint\n",
      "for i in range(1,99):\n",
      "    i = float(i)\n",
      "    expectedint[compinfo.fractionlost > 1.0 - 1.0/(1.0+i/100)] = i\n",
      "    \n",
      "compinfo.expectedint = expectedint\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/pandas/core/series.py:635: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\n",
        "  self.where(~key, value, inplace=True)\n",
        "/usr/lib/python2.7/dist-packages/pandas/core/generic.py:1830: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "  self[name] = value\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More merging of databases\n",
      "compinfo2 = pd.merge(compinfo,loanapplic,on = 'loanid')\n",
      "compinfo2 = pd.merge(compinfo2, borrowers, left_on = 'borrowerid', right_on = 'userid')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In this section, we are normalizing all payments to USD. I don't think this will be an issue for future databases and tables\n",
      "# since as I understand, you will actually be including the USD amount into the table as well\n",
      "groupexcratedf = excratedf.groupby('currency')\n",
      "groupexcratedf = groupexcratedf['rate'].apply(np.mean)\n",
      "groupexcratedf = groupexcratedf.reset_index()\n",
      "groupexcratedf = groupexcratedf.rename(columns={0: 'rate'})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The following sections are just converting to USD using the reported rate\n",
      "compinfo2 = pd.merge(compinfo2, groupexcratedf, how = \"left\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trueexpected = compinfo2.expectedamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truelossamt = compinfo2.lossamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truepaidamt = compinfo2.paidamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['trueexpected'] = trueexpected"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['truelossamt'] = truelossamt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['truepaidamt'] = truepaidamt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This part is a bit tricky. For tdata analysis, we want the data set to be uniform.\n",
      "# For the time that I spent working on this project, January 2014 represented the last major change\n",
      "# As a result, I only want to base the model on the most recent data sets\n",
      "currdate = datetime(2014,1,1)\n",
      "oneyeartime = time.mktime(currdate.timetuple())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sorting by fraction lost helps in later parts\n",
      "lastyear = compinfo2[(compinfo2.AcceptDate > oneyeartime)]\n",
      "lastyear = lastyear.sort('fractionlost')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is actually important. For this model, we are not considering fraud (which is why we remove all loss = 1)\n",
      "# In order for model improvement, I need to calculate default. If you look at zidisha script for determining interest rate\n",
      "# There is also a field for default\n",
      "# I think that this is a really good opportunity to drastically improve the model. If somebody can determine a model for predicting\n",
      "# only if a person will default (without including how much in they default), the predictions will be much better and it will\n",
      "# negate the need for this value\n",
      "lastyearnotfraud = lastyear[lastyear.fractionlost < 1]\n",
      "total = float(len(lastyearnotfraud))\n",
      "default = float(len(lastyearnotfraud[lastyearnotfraud.fractionlost > 0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Similar to the interest rate determination script, we have to deal with possible null values\n",
      "currentdf = lastyearnotfraud\n",
      "debt = currentdf.isdebtfree\n",
      "debt[isnan(debt)] = 0.646\n",
      "currentdf = currentdf.drop('isdebtfree', axis = 1)\n",
      "currentdf['isdebtfree'] = debt\n",
      "lci = currentdf.loan_category_id\n",
      "lci[isnan(lci)] = 19\n",
      "currentdf = currentdf.drop('loan_category_id', axis = 1)\n",
      "currentdf['loan_category_id'] = lci\n",
      "# Following part is also important. I have, based upon the logistic regression, determined the fields that are important\n",
      "# As you collect more and more data, and determine more important fields and outdated fields, make sure that you change what you are selecting\n",
      "# from Xsvm\n",
      "Xsvm = currentdf[['interest','currency','isdebtfree','loan_category_id']]\n",
      "ysvm = currentdf['fractionlost']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To validate the model we have to demonstrate that it is better than before and random\n",
      "# We will withhold 10% of the information to check to see that the model performs on non-trained data\n",
      "\n",
      "rows = np.random.choice(Xsvm.index, round(len(Xsvm)/10))\n",
      "currentdf_test = currentdf.ix[rows]\n",
      "Xsvm_test = Xsvm.ix[rows]\n",
      "ysvm_test = ysvm.ix[rows]\n",
      "Xsvm_train = Xsvm.drop(rows)\n",
      "ysvm_train = ysvm.drop(rows)\n",
      "currentdf_train = currentdf.drop(rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ysvm_train = np.ravel(ysvm_train)\n",
      "ysvm_test = np.ravel(ysvm_test)\n",
      "lin_clf = svm.SVC(kernel = 'poly', degree = 4, max_iter = 10000, tol = 1e-5)\n",
      "lin_clf.fit(Xsvm_train, ysvm_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# From this we generate the mean squared error from (sequentially) the model, previous determined values, and a randomly shuffled values\n",
      "# If the model is doing better, it should have a significantly smaller MSE than the other two cases\n",
      "print(np.sum((1.0 - 1.0/(1.0+currentdf_test.finalrate/100.0) - ysvm_test)**2)/len(predictvalues))\n",
      "print(np.sum((predictvalues - ysvm_test)**2)/len(predictvalues))\n",
      "random.shuffle(predictvalues)\n",
      "print(np.sum((predictvalues - ysvm_test)**2)/len(predictvalues))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'currentdf_test' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-1ecb705e58c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Frin this we generate the mean squared error from (sequentially) the model, previous determined values, and a randomly shuffled values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcurrentdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalrate\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mysvm_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mysvm_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mysvm_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'currentdf_test' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}