{
 "metadata": {
  "name": "",
  "signature": "sha256:aa5dbe742d18f903b8805783c880c6da5c9e10f514c8cccc952320aaece98d7d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You might not need all of these packages. For the most part a lot of these are used for plots to check\n",
      "# if your model is running well. I left the plots and other stuff in just for now but if you feel like you\n",
      "# do not need then, you should take some of these packages out\n",
      "import pandas as pd\n",
      "import pandas.io.sql as psql\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as mdates\n",
      "from datetime import datetime\n",
      "import MySQLdb as mdb \n",
      "import numpy as np\n",
      "import time\n",
      "import statsmodels.api as sm\n",
      "from patsy import dmatrices\n",
      "from sklearn import svm\n",
      "from sklearn.externals import joblib\n",
      "import pickle as pickle\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from scipy.stats import gaussian_kde\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Connection here needs to be changed. Note that for now, I am connected to old databases\n",
      "con = mdb.connect(host = 'localhost', user = 'root', passwd = 'pptz/90275', db = 'zidisha')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extraction from these tables also need to be changed. I am again using old tables and some of the names are different.\n",
      "# I left it like this for now because I know that many of the columns are going to change\n",
      "with con:\n",
      "    cur = con.cursor()\n",
      "    sql = \"SELECT * FROM excrate\"\n",
      "    excratedf = psql.frame_query(sql, con, coerce_float = True)\n",
      "\n",
      "    sql = \"SELECT * FROM borrowers\"\n",
      "    borrowers = psql.frame_query(sql, con, coerce_float = True)\n",
      "    \n",
      "    sql = \"SELECT * FROM repaymentschedule\"\n",
      "    rsh = psql.frame_query(sql, con, coerce_float = True)\n",
      "    \n",
      "    sql = \"SELECT * FROM loanapplic\"\n",
      "    loanapplic = psql.frame_query(sql, con, coerce_float = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is from the repayment schedule table\n",
      "# We are trying to get rid of lines in which there are no values otherwise this will throw error later on\n",
      "# Amount = Amount expected during each payment. Paid amount is amount for each installment\n",
      "rshamount = rsh.amount\n",
      "rshamount[np.isnan(rshamount)] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rshpaidamt = rsh.paidamt\n",
      "rshpaidamt[np.isnan(rshpaidamt)] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loss is calculated as the amount paid - amount lost\n",
      "rsh['netloss'] = pd.Series(rshpaidamt - rshamount, index=rsh.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To allow for 2 month grace period, we are going to only look at data that was at most 2 months ago.\n",
      "# Currently, this is calculated as 60 days before the current time\n",
      "currdate = datetime.now()\n",
      "twomonthtime = time.mktime(currdate.timetuple()) - 60*24*3600\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Isolating only the rows that fit within the time\n",
      "rshtrunc = rsh[rsh.duedate.apply(float)<twomonthtime]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We are going to merging some tables to centralize values for the loans\n",
      "rshgroup = rsh.groupby('loanid')\n",
      "rshtruncgroup = rshtrunc.groupby('loanid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lossamt = rshtruncgroup['netloss'].apply(sum)\n",
      "lossamt = lossamt.reset_index()\n",
      "lossamt = lossamt.rename(columns = {0:'lossamt'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expectedamt = rshtruncgroup['amount'].apply(sum)\n",
      "expectedamt = expectedamt.reset_index()\n",
      "expectedamt = expectedamt.rename(columns = {0:'expectedamt'})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paidamt = rshtruncgroup['paidamt'].apply(sum)\n",
      "paidamt = paidamt.reset_index()\n",
      "paidamt = paidamt.rename(columns = {0:'paidamt'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By fraction lost, this means that the fraction payments a person recieved before defaulting\n",
      "# For some people, they will actually have paid a little bit more, and this counts as full repayment so we set it to zero\n",
      "fractionlost = (lossamt.lossamt)/np.abs(expectedamt.expectedamt)\n",
      "fractionlost[fractionlost > 0.0]  = 0.0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Again, we are centralizing the information. Note, I want risk to be between 0 to 1 which is why we use the negative\n",
      "compinfo = expectedamt\n",
      "compinfo['lossamt'] = lossamt.lossamt\n",
      "compinfo['fractionlost'] = -fractionlost\n",
      "compinfo['paidamt'] = paidamt.paidamt\n",
      "compinfo = compinfo[compinfo.expectedamt != 0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This entire section is optional. It depends on how you want to train the svm. We can categorize by risk or by supposed interest rate\n",
      "# I do not recommend this because dividing by risk enhances the error for interest rate determination\n",
      "compinfo['expectedint'] = 1\n",
      "expectedint = compinfo.expectedint\n",
      "for i in range(1,99):\n",
      "    i = float(i)\n",
      "    expectedint[compinfo.fractionlost > 1.0 - 1.0/(1.0+i/100)] = i\n",
      "    \n",
      "compinfo.expectedint = expectedint\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/pandas/core/series.py:635: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\n",
        "  self.where(~key, value, inplace=True)\n",
        "/usr/lib/python2.7/dist-packages/pandas/core/generic.py:1830: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "  self[name] = value\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More merging of databases\n",
      "compinfo2 = pd.merge(compinfo,loanapplic,on = 'loanid')\n",
      "compinfo2 = pd.merge(compinfo2, borrowers, left_on = 'borrowerid', right_on = 'userid')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In this section, we are normalizing all payments to USD. I don't think this will be an issue for future databases and tables\n",
      "# since as I understand, you will actually be including the USD amount into the table as well\n",
      "groupexcratedf = excratedf.groupby('currency')\n",
      "groupexcratedf = groupexcratedf['rate'].apply(np.mean)\n",
      "groupexcratedf = groupexcratedf.reset_index()\n",
      "groupexcratedf = groupexcratedf.rename(columns={0: 'rate'})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The following sections are just converting to USD using the reported rate\n",
      "compinfo2 = pd.merge(compinfo2, groupexcratedf, how = \"left\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trueexpected = compinfo2.expectedamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truelossamt = compinfo2.lossamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "truepaidamt = compinfo2.paidamt/compinfo2.rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['trueexpected'] = trueexpected"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['truelossamt'] = truelossamt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compinfo2['truepaidamt'] = truepaidamt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This part is a bit tricky. For tdata analysis, we want the data set to be uniform.\n",
      "# For the time that I spent working on this project, January 2014 represented the last major change\n",
      "# As a result, I only want to base the model on the most recent data sets\n",
      "currdate = datetime(2014,1,1)\n",
      "oneyeartime = time.mktime(currdate.timetuple())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sorting by fraction lost helps in later parts\n",
      "lastyear = compinfo2[(compinfo2.AcceptDate > oneyeartime)]\n",
      "lastyear = lastyear.sort('fractionlost')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is actually important. For this model, we are not considering fraud (which is why we remove all loss = 1)\n",
      "# In order for model improvement, I need to calculate default. If you look at zidisha script for determining interest rate\n",
      "# There is also a field for default\n",
      "# I think that this is a really good opportunity to drastically improve the model. If somebody can determine a model for predicting\n",
      "# only if a person will default (without including how much in they default), the predictions will be much better and it will\n",
      "# negate the need for this value\n",
      "lastyearnotfraud = lastyear[lastyear.fractionlost < 1]\n",
      "total = float(len(lastyearnotfraud))\n",
      "default = float(len(lastyearnotfraud[lastyearnotfraud.fractionlost > 0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, cols_to_keep are the fields that you want to test. Since I was testing many things and ended here, I have only left these 4\n",
      "# If you want to test new and other fields, please make sure to include their name\n",
      "# Fractionlost must be included since that is your output value\n",
      "\n",
      "cols_to_keep = ['loan_category_id','currency','interest','fractionlost']\n",
      "data = lastyearnotfraud[cols_to_keep]\n",
      "\n",
      "# We don't want anything in logistic regression that has null values. Logistic regression only accepts actual numerical values\n",
      "data = data.dropna()\n",
      "\n",
      "y = data.fractionlost\n",
      "\n",
      "# We are separating the dependent and independent values\n",
      "data = data.drop('fractionlost',axis = 1)\n",
      "\n",
      "# We just need a intercept value to run things through logistic regression\n",
      "data['intercept'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The following part is just doing the logistic regression\n",
      "logit = sm.Logit(y, data)\n",
      "result = logit.fit()\n",
      "print(result.summary())\n",
      "# Finally, note that for now, I have only taken coefficient values of 0.01 with a p-value < 0.01 to train in the SVM script"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}